{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sven/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sven/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/sven/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/sven/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sven/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shap\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/sven/nltk_data', '/opt/anaconda3/nltk_data', '/opt/anaconda3/share/nltk_data', '/opt/anaconda3/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_file = \"training_data_lowercase.csv\"\n",
    "data = pd.read_csv(data_file, sep=\"\\t\", header=None)  # Load as tab-delimited file without headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  donald trump sends out embarrassing new year‚s...\n",
       "1      0  drunk bragging trump staffer started russian c...\n",
       "2      0  sheriff david clarke becomes an internet joke ...\n",
       "3      0  trump is so obsessed he even has obama‚s name ...\n",
       "4      0  pope francis just called out donald trump duri..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign new column names\n",
    "data.columns = ['label', 'text']\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters\n",
    "data['text'] = data['text'].str.replace(r'[^a-z0-9\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and remove stopwords for each text entry in the dataframe\n",
    "data['filtered_text'] = data['text'].apply(lambda x: [word for word in word_tokenize(x) if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text  \\\n",
      "0      0  donald trump sends out embarrassing new years ...   \n",
      "1      0  drunk bragging trump staffer started russian c...   \n",
      "2      0  sheriff david clarke becomes an internet joke ...   \n",
      "3      0  trump is so obsessed he even has obamas name c...   \n",
      "4      0  pope francis just called out donald trump duri...   \n",
      "\n",
      "                                       filtered_text  \\\n",
      "0  [donald, trump, sends, embarrassing, new, year...   \n",
      "1  [drunk, bragging, trump, staffer, started, rus...   \n",
      "2  [sheriff, david, clarke, becomes, internet, jo...   \n",
      "3  [trump, obsessed, even, obamas, name, coded, w...   \n",
      "4  [pope, francis, called, donald, trump, christm...   \n",
      "\n",
      "                                     lemmatized_text  \n",
      "0  [donald, trump, sends, embarrass, new, year, e...  \n",
      "1  [drunk, bragging, trump, staffer, start, russi...  \n",
      "2  [sheriff, david, clarke, becomes, internet, jo...  \n",
      "3  [trump, obsess, even, obamas, name, cod, websi...  \n",
      "4  [pope, francis, call, donald, trump, christmas...  \n"
     ]
    }
   ],
   "source": [
    "# Lemmatization of text to leverage the context as well\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import wordnet\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to get part-of-speech (POS) tagging for more accurate lemmatization\n",
    "def get_wordnet_pos(word):\n",
    "    from nltk.corpus import wordnet\n",
    "    from nltk import pos_tag\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,  # Adjective\n",
    "        'N': wordnet.NOUN,  # Noun\n",
    "        'V': wordnet.VERB,  # Verb\n",
    "        'R': wordnet.ADV   # Adverb\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)  # Default to noun\n",
    "\n",
    "# Apply lemmatization to the filtered_text column\n",
    "data['lemmatized_text'] = data['filtered_text'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n",
    ")\n",
    "\n",
    "# Display the first few rows to verify the result\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [donald, trump, sends, embarrass, new, year, e...\n",
      "1        [drunk, bragging, trump, staffer, start, russi...\n",
      "2        [sheriff, david, clarke, becomes, internet, jo...\n",
      "3        [trump, obsess, even, obamas, name, cod, websi...\n",
      "4        [pope, francis, call, donald, trump, christmas...\n",
      "                               ...                        \n",
      "34147      [tear, rain, thai, gather, late, king, funeral]\n",
      "34148    [pyongyang, university, need, nonus, teacher, ...\n",
      "34149    [philippine, president, duterte, visit, japan,...\n",
      "34150    [japan, abe, may, election, many, dont, want, pm]\n",
      "34151    [demoralize, divide, inside, catalonia, police...\n",
      "Name: lemmatized_text, Length: 34152, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens into single text strings for each row in 'lemmatized_text'\n",
    "data['lemmatized_text'] = data['lemmatized_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=100,  # Limit to top 5000 words \n",
    "    stop_words='english',  # Exclude common stopwords \n",
    "    ngram_range=(1, 2)  # Consider unigrams and bigrams \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends embarrass new year eve mess...\n",
      "1        drunk bragging trump staffer start russian col...\n",
      "2        sheriff david clarke becomes internet joke thr...\n",
      "3          trump obsess even obamas name cod website image\n",
      "4          pope francis call donald trump christmas speech\n",
      "                               ...                        \n",
      "34147              tear rain thai gather late king funeral\n",
      "34148    pyongyang university need nonus teacher travel...\n",
      "34149    philippine president duterte visit japan ahead...\n",
      "34150             japan abe may election many dont want pm\n",
      "34151      demoralize divide inside catalonia police force\n",
      "Name: lemmatized_text, Length: 34152, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the lemmatized text column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends embarrass new year eve mess...\n",
      "1        drunk bragging trump staffer start russian col...\n",
      "2        sheriff david clarke becomes internet joke thr...\n",
      "3          trump obsess even obamas name cod website image\n",
      "4          pope francis call donald trump christmas speech\n",
      "                               ...                        \n",
      "34147              tear rain thai gather late king funeral\n",
      "34148    pyongyang university need nonus teacher travel...\n",
      "34149    philippine president duterte visit japan ahead...\n",
      "34150             japan abe may election many dont want pm\n",
      "34151      demoralize divide inside catalonia police force\n",
      "Name: lemmatized_text, Length: 34152, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the resulting sparse matrix to a DataFrame for analysis\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends embarrass new year eve mess...\n",
      "1        drunk bragging trump staffer start russian col...\n",
      "2        sheriff david clarke becomes internet joke thr...\n",
      "3          trump obsess even obamas name cod website image\n",
      "4          pope francis call donald trump christmas speech\n",
      "                               ...                        \n",
      "34147              tear rain thai gather late king funeral\n",
      "34148    pyongyang university need nonus teacher travel...\n",
      "34149    philippine president duterte visit japan ahead...\n",
      "34150             japan abe may election many dont want pm\n",
      "34151      demoralize divide inside catalonia police force\n",
      "Name: lemmatized_text, Length: 34152, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    america  american    attack  ban     black    break  campaign  chief  \\\n",
      "0       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "1       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "2       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "3       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "4       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "5       0.0       0.0  0.000000  0.0  0.677261  0.00000  0.000000    0.0   \n",
      "6       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "7       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "8       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "9       0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "10      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "11      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "12      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "13      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "14      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "15      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "16      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "17      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "18      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "19      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "20      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "21      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "22      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "23      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "24      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "25      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.569852    0.0   \n",
      "26      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "27      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "28      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "29      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "30      0.0       0.0  0.000000  0.0  0.000000  1.00000  0.000000    0.0   \n",
      "31      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "32      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "33      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "34      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "35      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "36      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "37      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "38      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "39      0.0       0.0  0.475528  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "40      0.0       0.0  0.480705  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "41      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "42      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "43      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "44      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "45      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "46      0.0       0.0  0.000000  0.0  0.000000  0.91792  0.000000    0.0   \n",
      "47      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "48      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.550505    0.0   \n",
      "49      0.0       0.0  0.000000  0.0  0.000000  0.00000  0.000000    0.0   \n",
      "\n",
      "    china  clinton  ...     video  vote     voter      want     watch  \\\n",
      "0     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "1     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "2     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "3     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "4     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "5     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "6     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "7     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "8     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "9     0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "10    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "11    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "12    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "13    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "14    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "15    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "16    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "17    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "18    0.0      0.0  ...  0.519227   0.0  0.000000  0.000000  0.000000   \n",
      "19    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "20    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "21    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "22    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "23    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "24    0.0      0.0  ...  0.347956   0.0  0.000000  0.000000  0.000000   \n",
      "25    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "26    0.0      0.0  ...  0.519227   0.0  0.000000  0.000000  0.000000   \n",
      "27    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "28    0.0      0.0  ...  0.427645   0.0  0.000000  0.000000  0.000000   \n",
      "29    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "30    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "31    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "32    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "33    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "34    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "35    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "36    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "37    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "38    0.0      0.0  ...  0.000000   0.0  0.000000  0.685956  0.000000   \n",
      "39    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "40    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "41    0.0      0.0  ...  0.810502   0.0  0.000000  0.000000  0.000000   \n",
      "42    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "43    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "44    0.0      0.0  ...  0.377524   0.0  0.000000  0.000000  0.676932   \n",
      "45    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "46    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "47    0.0      0.0  ...  0.000000   0.0  0.000000  0.000000  0.000000   \n",
      "48    0.0      0.0  ...  0.000000   0.0  0.615841  0.000000  0.000000   \n",
      "49    0.0      0.0  ...  0.810502   0.0  0.000000  0.000000  0.000000   \n",
      "\n",
      "       white  white house       win  woman      year  \n",
      "0   0.000000     0.000000  0.000000    0.0  0.553761  \n",
      "1   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "2   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "3   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "4   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "5   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "6   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "7   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "8   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "9   0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "10  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "11  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "12  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "13  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "14  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "15  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "16  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "17  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "18  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "19  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "20  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "21  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "22  0.000000     0.000000  0.745675    0.0  0.000000  \n",
      "23  0.000000     0.000000  0.000000    0.0  0.477224  \n",
      "24  0.519720     0.556318  0.000000    0.0  0.000000  \n",
      "25  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "26  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "27  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "28  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "29  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "30  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "31  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "32  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "33  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "34  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "35  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "36  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "37  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "38  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "39  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "40  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "41  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "42  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "43  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "44  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "45  0.575448     0.615971  0.000000    0.0  0.000000  \n",
      "46  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "47  0.900170     0.000000  0.000000    0.0  0.000000  \n",
      "48  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "49  0.000000     0.000000  0.000000    0.0  0.000000  \n",
      "\n",
      "[50 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the TF-IDF DataFrame\n",
    "print(tfidf_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    donald trump sends embarrass new year eve mess...\n",
      "1    drunk bragging trump staffer start russian col...\n",
      "2    sheriff david clarke becomes internet joke thr...\n",
      "3      trump obsess even obamas name cod website image\n",
      "4      pope francis call donald trump christmas speech\n",
      "5    racist alabama cop brutalize black boy handcuf...\n",
      "6                                    fresh golf course\n",
      "7    trump say insanely racist stuff inside oval of...\n",
      "8           former cia director slam trump un bullying\n",
      "9     brandnew protrump ad feature much kiss make sick\n",
      "Name: lemmatized_text, dtype: object\n",
      "0\n",
      "count    34152.000000\n",
      "mean        59.058562\n",
      "std         17.687234\n",
      "min          0.000000\n",
      "25%         49.000000\n",
      "50%         57.000000\n",
      "75%         67.000000\n",
      "max        229.000000\n",
      "Name: lemmatized_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['lemmatized_text'].head(10))\n",
    "print(data['lemmatized_text'].isna().sum())  # Check for NaN values\n",
    "print(data['lemmatized_text'].apply(len).describe())  # Analyze lengths of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set and split into training and test\n",
    "\n",
    "X = tfidf_df\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Model\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train Random Forest Model\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Confusion Matrix:\n",
      "[[2625  904]\n",
      " [ 381 2921]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      3529\n",
      "           1       0.76      0.88      0.82      3302\n",
      "\n",
      "    accuracy                           0.81      6831\n",
      "   macro avg       0.82      0.81      0.81      6831\n",
      "weighted avg       0.82      0.81      0.81      6831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.0s\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Score: 0.8011053768163684\n"
     ]
    }
   ],
   "source": [
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available processors\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train a model with the best parameters\n",
    "optimized_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.81174059434929\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = optimized_rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=120; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=120; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=120; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=9, n_estimators=230; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=9, n_estimators=230; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=370; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=370; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=6, n_estimators=370; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=9, n_estimators=230; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=443; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=443; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=9, n_estimators=472; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=9, n_estimators=472; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=9, n_estimators=472; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=443; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=158; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=6, n_estimators=260; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=6, n_estimators=260; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=158; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=158; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=6, n_estimators=260; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=9, n_estimators=287; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=154; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=154; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=352; total time=   4.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=352; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=9, n_estimators=287; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=352; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=154; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=485; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=9, n_estimators=287; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=485; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=7, n_estimators=485; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=7, n_estimators=274; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=7, n_estimators=274; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=7, n_estimators=274; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=120; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=120; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=230; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=120; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=230; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=230; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=152; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=152; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=152; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=180; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=180; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=466; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=466; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=466; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=7, n_estimators=153; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=180; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=7, n_estimators=341; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=363; total time=   4.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=7, n_estimators=341; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=363; total time=   4.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=5, n_estimators=363; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=7, n_estimators=341; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=7, n_estimators=153; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=7, n_estimators=153; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=261; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=7, n_estimators=290; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=7, n_estimators=290; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=7, n_estimators=290; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=3, n_estimators=487; total time=   8.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=3, n_estimators=487; total time=   9.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=261; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=261; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=3, n_estimators=487; total time=   9.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=369; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=369; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=369; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=9, n_estimators=487; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=9, n_estimators=487; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=9, n_estimators=487; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=8, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=8, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=8, n_estimators=314; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=140; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=140; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=9, n_estimators=316; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=140; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=7, n_estimators=395; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=7, n_estimators=395; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=7, n_estimators=395; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=9, n_estimators=316; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=9, n_estimators=316; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=164; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=164; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=6, n_estimators=164; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=437; total time=   7.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=9, n_estimators=162; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=9, n_estimators=162; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=9, n_estimators=162; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=437; total time=   7.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=6, n_estimators=437; total time=   8.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   5.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=140; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=140; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=8, n_estimators=140; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=478; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=478; total time=   5.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=443; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=443; total time=   8.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=147; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=2, n_estimators=478; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=147; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=147; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=443; total time=   8.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=427; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=315; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=427; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=315; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=7, n_estimators=315; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=326; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=326; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=326; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=427; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=141; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=7, n_estimators=230; total time=   4.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=7, n_estimators=230; total time=   4.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=141; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=7, n_estimators=230; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=492; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=3, n_estimators=141; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=492; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=4, n_estimators=492; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=4, n_estimators=162; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=4, n_estimators=162; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=151; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=4, n_estimators=162; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=151; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=3, min_samples_split=2, n_estimators=151; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5, n_estimators=459; total time=   8.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5, n_estimators=459; total time=   8.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5, n_estimators=459; total time=   8.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=3, n_estimators=354; total time=   7.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=3, n_estimators=354; total time=   7.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=3, n_estimators=354; total time=   7.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=321; total time=   4.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=321; total time=   5.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=321; total time=   4.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=336; total time=   5.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=336; total time=   4.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=8, n_estimators=336; total time=   4.8s\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 140}\n",
      "Best Score: 0.801398191867062\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),  # Random values between 100 and 500\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of random combinations to try\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available processors\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)\n",
    "\n",
    "# Train a model with the best parameters\n",
    "optimized_rf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.8123261601522471\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = optimized_rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.3-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:27:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,   # Number of trees\n",
    "    learning_rate=0.1,  # Step size shrinkage\n",
    "    max_depth=6,        # Maximum depth of a tree\n",
    "    use_label_encoder=False,  # Avoid unnecessary label encoding warnings\n",
    "    eval_metric='logloss'  # Evaluation metric for classification\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78      3529\n",
      "           1       0.73      0.93      0.82      3302\n",
      "\n",
      "    accuracy                           0.80      6831\n",
      "   macro avg       0.82      0.81      0.80      6831\n",
      "weighted avg       0.82      0.80      0.80      6831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=150, subsample=1.0; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=50, subsample=1.0; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=150, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:30:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 150, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the final model with best parameters\n",
    "best_xgb_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.8089591567852438\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert feature names to a list\n",
    "best_xgb_model.get_booster().feature_names = list(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(best_xgb_model, max_num_features=20)  # Optional: limit to top 20 features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.46.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/anaconda3/lib/python3.12/site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.12/site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.46.0-cp312-cp312-macosx_11_0_arm64.whl (455 kB)\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.46.0 slicer-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# For binary classification, shap_values returns a list with two arrays:\n",
    "# shap_values[0] - Contributions for class 0 (real news)\n",
    "# shap_values[1] - Contributions for class 1 (fake news)\n",
    "\n",
    "# Plot for class 0 (real news)\n",
    "shap.summary_plot(shap_values[0], X_test, feature_names=tfidf_vectorizer.get_feature_names_out(), show=True)\n",
    "\n",
    "# Plot for class 1 (fake news)\n",
    "shap.summary_plot(shap_values[1], X_test, feature_names=tfidf_vectorizer.get_feature_names_out(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of SHAP values for class 0 (real news): (100,)\n",
      "Shape of SHAP values for class 1 (fake news): (100,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Summary plots need a matrix of shap_values, not a vector.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of SHAP values for class 1 (fake news):\u001b[39m\u001b[38;5;124m\"\u001b[39m, shap_values[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Now plot for class 0 (real news)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values[\u001b[38;5;241m0\u001b[39m], X_test, feature_names\u001b[38;5;241m=\u001b[39mtfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out(), show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Now plot for class 1 (fake news)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values[\u001b[38;5;241m1\u001b[39m], X_test, feature_names\u001b[38;5;241m=\u001b[39mtfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out(), show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/shap/plots/_beeswarm.py:506\u001b[0m, in \u001b[0;36msummary_legacy\u001b[0;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         plot_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# default for single output explanations\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shap_values\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary plots need a matrix of shap_values, not a vector.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# default color:\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Summary plots need a matrix of shap_values, not a vector."
     ]
    }
   ],
   "source": [
    "# Create the SHAP explainer\n",
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "\n",
    "# Get the SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Check the shape of SHAP values for both classes (real news and fake news)\n",
    "print(\"Shape of SHAP values for class 0 (real news):\", shap_values[0].shape)\n",
    "print(\"Shape of SHAP values for class 1 (fake news):\", shap_values[1].shape)\n",
    "\n",
    "# Now plot for class 0 (real news)\n",
    "shap.summary_plot(shap_values[0], X_test, feature_names=tfidf_vectorizer.get_feature_names_out(), show=True)\n",
    "\n",
    "# Now plot for class 1 (fake news)\n",
    "shap.summary_plot(shap_values[1], X_test, feature_names=tfidf_vectorizer.get_feature_names_out(), show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
